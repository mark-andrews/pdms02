{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = request.urlopen('https://www.bbc.co.uk/news/science-environment-52587488').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Share this with\n",
      "\n",
      "\n",
      "Email\n",
      "\n",
      "\n",
      "Facebook\n",
      "\n",
      "\n",
      "Messenger\n",
      "\n",
      "\n",
      "Messenger\n",
      "\n",
      "\n",
      "Twitter\n",
      "\n",
      "\n",
      "Pinterest\n",
      "\n",
      "\n",
      "WhatsApp\n",
      "\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "\n",
      "Copy this link\n",
      "\n",
      "\n",
      "These are external links and will open in a new window\n",
      "\n",
      "\n",
      "Astronomers have produced a remarkable new image of Jupiter, tracing the glowing regions of warmth that lurk beneath the gas giant's cloud tops.\n",
      "\n",
      "\n",
      "The picture was captured in infared by the Gemini North Telescope in Hawaii, and is one of the sharpest observations of the planet ever made from the ground.\n",
      "\n",
      "\n",
      "To achieve the resolution, scientists used a technique called \"lucky imaging\" which scrubs out the blurring effect of looking through Earth's turbulent atmosphere.\n",
      "\n",
      "\n",
      "This method involves acquiring multiple exposures of the target and only keeping those segments of an image where that turbulence is at a minimum.\n",
      "\n",
      "\n",
      "When all the \"lucky shots\" are put together in a mosaic, a clarity emerges that's beyond just the single exposure.\n",
      "\n",
      "\n",
      "Infrared is a longer wavelength than the more familiar visible light detected by the likes of the Hubble telescope. It is used to see past the haze and thin clouds at the top of Jupiter's atmosphere, to give scientists the opportunity to probe deeper into the planet's internal workings.\n",
      "\n",
      "\n",
      "Researchers want to understand better what makes and sustains the gas giant's weather systems, and in particular the great storms that can rage for decades and even centuries.  \n",
      "\n",
      "\n",
      "The study that produced this infrared image was led from the University of California at Berkeley. It was part of a joint programme of observations that involved Hubble and the Juno spacecraft that's currently orbiting the fifth planet from the Sun.   \n",
      "\n",
      "\n",
      "Fast facts about Jupiter\n",
      "\n",
      "\n",
      "Jonathan.Amos-INTERNET@bbc.co.uk and follow me on Twitter: @BBCAmos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('p'):\n",
    "    print(p.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = soup.find_all('p')[15].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('method', 'NN'),\n",
       " ('involves', 'VBZ'),\n",
       " ('acquiring', 'VBG'),\n",
       " ('multiple', 'JJ'),\n",
       " ('exposures', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('target', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('only', 'RB'),\n",
       " ('keeping', 'VBG'),\n",
       " ('those', 'DT'),\n",
       " ('segments', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('image', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('that', 'DT'),\n",
       " ('turbulence', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('minimum', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'method',\n",
       " 'involves',\n",
       " 'acquiring',\n",
       " 'multiple',\n",
       " 'exposures',\n",
       " 'of',\n",
       " 'the',\n",
       " 'target',\n",
       " 'and',\n",
       " 'only',\n",
       " 'keeping',\n",
       " 'those',\n",
       " 'segments',\n",
       " 'of',\n",
       " 'an',\n",
       " 'image',\n",
       " 'where',\n",
       " 'that',\n",
       " 'turbulence',\n",
       " 'is',\n",
       " 'at',\n",
       " 'a',\n",
       " 'minimum.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[15].text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using a XML file `KRP.xml`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmlpage = open('KRP.xml').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(xmlpage, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr \n",
      "President \n",
      "Ladies \n",
      "and \n",
      "Gentlemen \n",
      "as \n",
      "the \n",
      "Chairman \n",
      "of \n",
      "South \n",
      "Cambridgeshire \n",
      "District \n",
      "Council \n",
      "it \n",
      "does \n",
      "give \n",
      "me \n",
      "great \n",
      "pleasure \n",
      "to \n",
      "welcome \n",
      "the \n",
      "Institute \n",
      "of \n",
      "Environmental \n",
      "Health \n",
      "Officers \n",
      "to \n",
      "Girton \n",
      "College \n",
      "here \n",
      "in \n",
      "South \n",
      "Cambridgeshire \n",
      "this \n",
      "morning\n"
     ]
    }
   ],
   "source": [
    "for word in soup.find_all('s')[0].find_all('w'):\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
